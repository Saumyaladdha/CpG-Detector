{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CpG Site Detection Using LSTM**\n"
      ],
      "metadata": {
        "id": "lvVaU8dKu6J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview**\n",
        "\n",
        "This notebook implements an LSTM-based model to detect and count CpG sites in DNA sequences. The model processes DNA sequences (strings of N, A, C, G, T) and predicts the number of CG dimers present.\n",
        "\n",
        "\n",
        "**Prerequisites**\n",
        "\n",
        "PyTorch\n",
        "NumPy\n",
        "Basic understanding of DNA sequences and CpG sites\n",
        "\n",
        "**Contents**\n",
        "\n",
        "Data Preparation & Processing\n",
        "Model Implementation\n",
        "Training Pipeline\n",
        "Evaluation & Testing\n",
        "Results Analysis"
      ],
      "metadata": {
        "id": "C5kRAZdku9i3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORsb5TqypNJK",
        "outputId": "c473a623-2c37-4056-84e1-ee4964d89e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from typing import Sequence\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "metadata": {
        "id": "V3zlTpnBp8b0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 1: Understanding the Problem\n",
        "- We need to count CpG sites (where C is followed by G) in DNA sequences\n",
        "- This is a sequence analysis problem where context matters\n",
        "- LSTM is suitable because:\n",
        "  1. It can capture sequential patterns\n",
        "  2. It has memory to remember previous nucleotides\n",
        "  3. It can handle variable-length sequences"
      ],
      "metadata": {
        "id": "CE77O4iBvU32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=13):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(13)"
      ],
      "metadata": {
        "id": "50Dn-_dYvPnI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 2: Data Representation\n",
        "- DNA sequences use NACGT alphabet\n",
        "- Need to convert between:\n",
        "  * DNA sequences (strings)\n",
        "  * Integer encodings (for model input)\n",
        "- One-hot encoding will be used for model input"
      ],
      "metadata": {
        "id": "zRV5ARCbvckj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dnaseq_to_intseq(sequence):\n",
        "    \"\"\"Convert a DNA sequence to integer encoding, handling invalid characters\"\"\"\n",
        "    return [dna2int.get(base, 0) for base in sequence]  # Default to 'N' -> 0\n"
      ],
      "metadata": {
        "id": "dRQ9EClXvemw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 3: Data Generation\n",
        "- Need synthetic data for training\n",
        "- Should generate:\n",
        "  * Random DNA sequences\n",
        "  * Corresponding CpG counts\n",
        "- Must ensure balanced representation of CpG sites"
      ],
      "metadata": {
        "id": "cLu4ijbDvj7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:\n",
        "    \"\"\"Generate random DNA sequences\"\"\"\n",
        "    for i in range(n_seqs):\n",
        "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
        "\n",
        "def count_cpgs(seq: str) -> int:\n",
        "    \"\"\"Count CpG sites in sequence\"\"\"\n",
        "    cgs = 0\n",
        "    for i in range(0, len(seq) - 1):\n",
        "        if seq[i:i+2] == \"CG\":\n",
        "            cgs += 1\n",
        "    return cgs\n",
        "\n",
        "def prepare_data(num_samples=100):\n",
        "    \"\"\"Prepare training data with labels\"\"\"\n",
        "    X_dna_seqs = list(rand_sequence(num_samples))\n",
        "    temp = [''.join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs]\n",
        "    y_dna_seqs = [count_cpgs(seq) for seq in temp]\n",
        "    return X_dna_seqs, y_dna_seqs"
      ],
      "metadata": {
        "id": "SgvDHH0Lvkwx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 4: Dataset Organization\n",
        "- Need custom Dataset class for PyTorch\n",
        "- Must handle:\n",
        "  * Batch processing\n",
        "  * Tensor conversion\n",
        "  * Length tracking"
      ],
      "metadata": {
        "id": "EQ_kdzwgvs1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNADataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.sequences[idx]), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "O7hLU67hvq4-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 5: Model Architecture\n",
        "- LSTM-based architecture choices:\n",
        "  * Bidirectional: No (not needed for simple counting)\n",
        "  * Layers: 2 (balance between complexity and efficiency)\n",
        "  * Hidden size: 128 (sufficient for pattern recognition)\n",
        "  * Dropout: 0.2 (prevent overfitting)"
      ],
      "metadata": {
        "id": "YUsWGIAQvych"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CpGPredictor(nn.Module):\n",
        "    def __init__(self, input_size=5, hidden_size=128, num_layers=2):\n",
        "        super(CpGPredictor, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.2\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.one_hot(x, num_classes=5).float()\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        final_hidden = lstm_out[:, -1, :]\n",
        "        return self.classifier(final_hidden).squeeze()"
      ],
      "metadata": {
        "id": "36FpQdPyvyDl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 6: Training Configuration\n",
        "- Hyperparameters chosen:\n",
        "  * Batch size: 32 (standard choice)\n",
        "  * Learning rate: 0.001 (typical for Adam)\n",
        "  * Epochs: 10 (sufficient for convergence)\n",
        "  * Loss: MSE (regression problem)"
      ],
      "metadata": {
        "id": "zUOcKTfRv5Db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "EBT8Obk1v4zm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 7: Training Implementation\n",
        "Now let's put it all together and train the moDEL"
      ],
      "metadata": {
        "id": "WVHIn4ruwFGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Configuration\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 0.001\n",
        "    EPOCHS = 10\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare data\n",
        "    print(\"Preparing data...\")\n",
        "    train_x, train_y = prepare_data(2048)  # 2048 training samples\n",
        "    test_x, test_y = prepare_data(512)     # 512 test samples\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = DNADataset(train_x, train_y)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Initialize model and training components\n",
        "    print(\"Initializing model...\")\n",
        "    model = CpGPredictor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Train\n",
        "    print(\"Starting training...\")\n",
        "    train_model(model, train_loader, criterion, optimizer, EPOCHS, device)\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'cpg_model.pth')\n",
        "    print(\"Training completed and model saved!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En3hczzlwGM1",
        "outputId": "f936dad5-b72d-4b98-8edc-6fab793a8d89"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Initializing model...\n",
            "Starting training...\n",
            "Epoch 1/10, Loss: 10.3543\n",
            "Epoch 2/10, Loss: 5.0045\n",
            "Epoch 3/10, Loss: 5.0137\n",
            "Epoch 4/10, Loss: 4.9410\n",
            "Epoch 5/10, Loss: 5.0291\n",
            "Epoch 6/10, Loss: 4.9241\n",
            "Epoch 7/10, Loss: 4.9731\n",
            "Epoch 8/10, Loss: 4.8853\n",
            "Epoch 9/10, Loss: 5.0450\n",
            "Epoch 10/10, Loss: 4.9507\n",
            "Training completed and model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THOUGHT PROCESS 8: Testing the Model\n",
        "Let's create a simple function to test our model on new sequenc"
      ],
      "metadata": {
        "id": "MjdglKg-wM5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_cpgs(model, sequence):\n",
        "    \"\"\"Predict CpG count for a given sequence\"\"\"\n",
        "    # Ensure the sequence contains only valid characters (NACGT)\n",
        "    valid_chars = set('NACGT')\n",
        "    if not all(char in valid_chars for char in sequence):\n",
        "        raise ValueError(\"Sequence contains invalid characters. Only 'N', 'A', 'C', 'G', 'T' are allowed.\")\n",
        "\n",
        "    int_seq = list(dnaseq_to_intseq(sequence))  # Convert sequence to integer indices\n",
        "    input_tensor = torch.tensor([int_seq]).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(input_tensor)\n",
        "\n",
        "    return prediction.item()\n"
      ],
      "metadata": {
        "id": "rVVTS09nwCtM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "model = CpGPredictor().to(device)\n",
        "model.load_state_dict(torch.load('/content/cpg_model.pth'))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Now you can use the model for predictions\n",
        "test_sequence = \"NCACANNTNCGGAGGCGNA\"\n",
        "predicted = predict_cpgs(model, test_sequence)\n",
        "print(f\"Predicted CpGs: {predicted:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwQ6xOj-1rOc",
        "outputId": "de60343b-801d-472e-e143-09f2cf6f895d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted CpGs: 5.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-49c50a898075>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/cpg_model.pth'))\n"
          ]
        }
      ]
    }
  ]
}